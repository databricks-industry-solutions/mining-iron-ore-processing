bundle:
  # TODO: Update this
  name: dbx-dabs-demo

########## Variables - Configure these to match your environment ##########

variables:
  catalog_name:
    description: "The name of the catalog to deploy to for this demo"
    #### Replace with your catalog ####
    default: default # replace this default: <my_catalog>

  # The "warehouse_id" variable is used to reference the warehouse used by the dashboard and genie space.
  warehouse_id:
    lookup:
      #### Replace this with the name of your SQL warehouse. ####
      warehouse: "Starter Warehouse" # replace this warehouse: <my_warehouse>

########## End of Variables ##########
      
  # Environment variable used for deployment paths
  environment:
    description: "Deployment environment (dev, staging, prod)"
    default: "dev"

targets:
  dev:
    default: true
    mode: development

# See more about resource configuration at https://docs.databricks.com/aws/en/dev-tools/bundles/resources
resources:

  schemas:
      mining-processing-demo:
        name: mining_iop_demo
        catalog_name: ${var.catalog_name}
        comment: This schema was created by Databricks Asset Bundles.
  
  volumes:
    raw_data:
      catalog_name: ${resources.schemas.mining-processing-demo.catalog_name}
      name: raw_data
      schema_name: ${resources.schemas.mining-processing-demo.name}

  registered_models:
    fe_model:
      name: fe_model
      catalog_name: ${resources.schemas.mining-processing-demo.catalog_name}
      schema_name: ${resources.schemas.mining-processing-demo.name}
      grants:
        - privileges:
            - EXECUTE
          principal: account users
    si_model:
      name: si_model
      catalog_name: ${resources.schemas.mining-processing-demo.catalog_name}
      schema_name: ${resources.schemas.mining-processing-demo.name}
      grants:
        - privileges:
            - EXECUTE
          principal: account users


#  apps:
#    demo_app:
#      name: "processing-demo-app"
#      description: "Simple Streamlit demo app"
#      source_code_path: "/Workspace/Users/${workspace.current_user.userName}/.bundle/${bundle.name}/${var.environment}/files/apps/src"

  dashboards:
    demo_dashboard:
      display_name: "Demo Dashboard"
      file_path: "./dashboards/Fe Concentrator Prediction Dashboard.lvdash.json"
      warehouse_id: "${var.warehouse_id}"

# This is the installation workflow. It will be run when the bundle is deployed.
  jobs:
    demo_workflow:
      parameters:
        - name: catalog_name
          default: ${resources.schemas.mining-processing-demo.catalog_name}
        - name: schema_name
          default: ${resources.schemas.mining-processing-demo.name}
        - name: volume_name
          default: ${resources.volumes.raw_data.name}
        - name: load_config_from_file
          default: "false"
      name: "deploy-iops-demo-workflow"
      tasks:
        - task_key: create-data-files
          notebook_task:
            notebook_path: "./notebooks/demo_setup/00b.create_data_files.ipynb"
            source: WORKSPACE
        - task_key: run-demo-pipeline
          pipeline_task:
            pipeline_id: "${resources.pipelines.demo_pipeline.id}"
            full_refresh: true
          depends_on:
            - task_key: create-data-files
        - task_key: run-governance-notebook
          notebook_task:
            notebook_path: "./notebooks/mining_iron_ore_processing_demo/01b. Unity Catalog, Governance and Auditability.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-demo-pipeline
        - task_key: run-eda-featurestore-notebook
          notebook_task:
            notebook_path: "./notebooks/mining_iron_ore_processing_demo/02. EDA and Feature Store.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-governance-notebook
        - task_key: run-model-creation-notebook
          notebook_task:
            notebook_path: "./notebooks/mining_iron_ore_processing_demo/03. Model Training and Experimentation.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-eda-featurestore-notebook
        - task_key: create-genie-space
          notebook_task:
            notebook_path: "./notebooks/demo_setup/03.create_genie_space.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-model-creation-notebook
        - task_key: create-serving-endpoints
          notebook_task:
            notebook_path: "./notebooks/demo_setup/05.create_serving_endpoints.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-model-creation-notebook
        - task_key: run-optimization-notebook
          notebook_task:
            notebook_path: "./notebooks/mining_iron_ore_processing_demo/05. Optimisation.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-model-creation-notebook
        - task_key: enable-anomaly-detection-classification
          notebook_task:
            notebook_path: "./notebooks/demo_setup/06.enable_data_classification_and_anomaly_detection.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-model-creation-notebook

  pipelines:
    demo_pipeline:
      name: "Mining Iron Ore Processing DLT Pipeline"
      catalog: ${resources.schemas.mining-processing-demo.catalog_name}
      configuration:
        catalog_name: ${resources.schemas.mining-processing-demo.catalog_name}
        schema_name: ${resources.schemas.mining-processing-demo.name}
        volume_name: ${resources.volumes.raw_data.name}

      libraries:
        - notebook:
            path: "notebooks/mining_iron_ore_processing_demo/01a. Data Engineering.ipynb"
      serverless: true
      photon: true
      development: true

# For more options and schema, see: https://docs.databricks.com/aws/en/dev-tools/bundles/settings
