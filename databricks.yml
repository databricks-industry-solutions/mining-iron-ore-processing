bundle:
  name: dbx-dabs-demo

variables:
  # The "warehouse_id" variable is used to reference the warehouse used by the dashboard.
  warehouse_id:
    lookup:
      # Replace this with the name of your SQL warehouse.
      warehouse: "dbdemos-shared-endpoint"
      
  # Environment variable used for deployment paths
  environment:
    description: "Deployment environment (dev, staging, prod)"
    default: "dev"

targets:
  dev:
    default: true
    mode: development

# See more about resource configuration at https://docs.databricks.com/aws/en/dev-tools/bundles/resources
resources:

  schemas:
      mining-processing-demo:
        name: mining_iop_demo
        catalog_name: jack_demos
        comment: This schema was created by Databricks Asset Bundles.

  apps:
    demo_app:
      name: "processing-demo-app"
      description: "Simple Streamlit demo app"
      source_code_path: "/Workspace/Users/${workspace.current_user.userName}/.bundle/${bundle.name}/${var.environment}/files/apps/src"

  dashboards:
    demo_dashboard:
      display_name: "Demo Dashboard"
      file_path: "./dashboards/Fe Concentrator Prediction Dashboard.lvdash.json"
      warehouse_id: "${var.warehouse_id}"

# This is the installation workflow. It will be run when the bundle is deployed.
  jobs:
    demo_workflow:
      name: "deploy-iops-demo-workflow"
      tasks:
        - task_key: create-sql-objects
          notebook_task:
            notebook_path: "./notebooks/demo_setup/00a.create_sql_objects.ipynb"
            source: WORKSPACE
        - task_key: create-data-files
          notebook_task:
            notebook_path: "./notebooks/demo_setup/00b.create_data_files.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: create-sql-objects
        - task_key: create-deployment-job
          notebook_task:
            notebook_path: "./notebooks/demo_setup/02.create-deployment-job.py"
            source: WORKSPACE
          depends_on:
            - task_key: create-data-files
        - task_key: run-governance-notebook
          notebook_task:
            notebook_path: "./notebooks/mining_iron_ore_processing_demo/01b. Unity Catalog, Governance and Auditability.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: create-deployment-job
        - task_key: run-eda-featurestore-notebook
          notebook_task:
            notebook_path: "./notebooks/mining_iron_ore_processing_demo/02. EDA and Feature Store.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-governance-notebook
        - task_key: run-model-creation-notebook
          notebook_task:
            notebook_path: "./notebooks/mining_iron_ore_processing_demo/03. Model Training and Experimentation.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-eda-featurestore-notebook
        - task_key: create-genie-space
          notebook_task:
            notebook_path: "./notebooks/demo_setup/03.create_genie_space.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-model-creation-notebook
        - task_key: create-serving-endpoints
          notebook_task:
            notebook_path: "./notebooks/demo_setup/05.create_serving_endpoints.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-model-creation-notebook
        - task_key: run-optimization-notebook
          notebook_task:
            notebook_path: "./notebooks/mining_iron_ore_processing_demo/05. Optimisation.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-model-creation-notebook
        - task_key: enable-anomaly-detection-classification
          notebook_task:
            notebook_path: "./notebooks/demo_setup/06.enable_data_classification_and_anomaly_detection.ipynb"
            source: WORKSPACE
          depends_on:
            - task_key: run-model-creation-notebook

  pipelines:
    demo_pipeline:
      name: "Mining Iron Ore Processing DLT Pipeline"
      catalog: ${resources.schemas.mining-processing-demo.catalog_name}
      target: ${resources.schemas.mining-processing-demo.name}
      configuration:
        catalog_name: ${resources.schemas.mining-processing-demo.catalog_name}
        schema_name: ${resources.schemas.mining-processing-demo.name}
        volume_name: "mining_processing_demo_volume"
      libraries:
        - notebook:
            path: "notebooks/mining_iron_ore_processing_demo/01a. Data Engineering.ipynb"
      serverless: true
      photon: true
      development: true

# Example resources you can uncomment and customize:
# resources:
#   apps:
#     your_app:
#       name: "your-app-name"
#       description: "Your app description"
#       source_code_path: "./apps/your_app"
#
#   jobs:
#     your_workflow:
#       name: "Your Workflow Name"
#       tasks:
#         - task_key: first_task
#           notebook_task:
#             notebook_path: "./notebooks/your_first_notebook.ipynb"
#         - task_key: second_task
#           depends_on:
#             - task_key: first_task
#           notebook_task:
#             notebook_path: "./notebooks/your_second_notebook.ipynb"
#
#   pipelines:
#     your_pipeline:
#       name: "Your Pipeline"
#       storage: "/Shared/your-pipeline"
#       configuration:
#         your_config: "value"
#
#
#   dashboards:
#     your_dashboard:
#       display_name: "Your Dashboard"
#       file_path: "./dashboards/your_dashboard.lvdash.json"

# For more options and schema, see: https://docs.databricks.com/aws/en/dev-tools/bundles/settings
