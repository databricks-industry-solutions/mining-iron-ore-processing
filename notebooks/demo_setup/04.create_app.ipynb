{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e5b2a2b1-a4ad-443f-b07e-5b74e831544d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk>=0.57.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fcaa2af-f51a-4099-8646-d6082866fd8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./_init\n",
    "\n",
    "# Get username parameter and clean it\n",
    "raw_username = dbutils.widgets.get(\"username\")\n",
    "# Extract part before @ and replace dots with underscores\n",
    "username = raw_username.split('@')[0].replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2ea0adf-4e06-48bf-ac22-e11461dfbd24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "#create app.yaml\n",
    "data = {\n",
    "    \"command\": [\n",
    "        \"streamlit\",\n",
    "        \"run\",\n",
    "        \"app.py\"\n",
    "    ],\n",
    "    \"env\": [\n",
    "        {\n",
    "            \"name\": \"DATABRICKS_WAREHOUSE_ID\",\n",
    "            \"valueFrom\": \"sql-warehouse\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"STREAMLIT_BROWSER_GATHER_USAGE_STATS\",\n",
    "            \"value\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TABLE_NAME\",\n",
    "            \"value\": f\"{catalog_name}.{schema_name}.gold_iop_features_version_demo\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"FE_ENDPOINT_NAME\",\n",
    "            \"value\": f\"{username}-fe_model-serving-endpoint\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"SI_ENDPOINT_NAME\",\n",
    "            \"value\": f\"{username}-si_model-serving-endpoint\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"../../apps/src/app.yaml\", \"w\") as f:\n",
    "    yaml.dump(data, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "127ae6eb-9c40-4b8c-976f-bd611e5e6341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#get default warehouse\n",
    "# Import necessary modules from the Databricks SDK\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service import sql\n",
    "\n",
    "# --- Configuration and Initialization ---\n",
    "# Initialize the Databricks WorkspaceClient.\n",
    "# If running this code directly in a Databricks notebook,\n",
    "# the client will automatically pick up authentication from the notebook's context.\n",
    "# If running locally, ensure your Databricks authentication is configured (e.g., via\n",
    "# DATABRICKS_HOST and DATABRICKS_TOKEN environment variables, or ~/.databrickscfg).\n",
    "w = WorkspaceClient()\n",
    "\n",
    "print(\"Attempting to find the first available SQL warehouse ID...\")\n",
    "\n",
    "try:\n",
    "    # 1. List all SQL warehouses\n",
    "    # The list() method returns an iterator of sql.Warehouse objects.\n",
    "    # We convert it to a list to enable sorting.\n",
    "    all_warehouses = list(w.warehouses.list())\n",
    "\n",
    "    if not all_warehouses:\n",
    "        print(\"No SQL warehouses found in this workspace.\")\n",
    "        print(\"Please ensure you have at least one SQL warehouse created.\")\n",
    "    else:\n",
    "        # 2. Separate running and stopped warehouses\n",
    "        running_warehouses = []\n",
    "        stopped_warehouses = []\n",
    "        for wh in all_warehouses:\n",
    "            if wh.state == sql.State.RUNNING:\n",
    "                running_warehouses.append(wh)\n",
    "            else:\n",
    "                stopped_warehouses.append(wh)\n",
    "\n",
    "        # 3. Sort both lists alphabetically by name\n",
    "        running_warehouses.sort(key=lambda wh: wh.name.lower())\n",
    "        stopped_warehouses.sort(key=lambda wh: wh.name.lower())\n",
    "\n",
    "        first_available_warehouse = None\n",
    "\n",
    "        if running_warehouses:\n",
    "            # Prioritize running warehouses\n",
    "            first_available_warehouse = running_warehouses[0]\n",
    "            print(\"Found a running SQL warehouse.\")\n",
    "        elif stopped_warehouses:\n",
    "            # If no running, take the first stopped one\n",
    "            first_available_warehouse = stopped_warehouses[0]\n",
    "            print(\"No running SQL warehouses found. Selecting the first available (stopped) warehouse.\")\n",
    "        else:\n",
    "            # This case should ideally be caught by `if not all_warehouses:` but as a fallback\n",
    "            print(\"No running or stopped SQL warehouses found.\")\n",
    "\n",
    "        if first_available_warehouse:\n",
    "            warehouse_id = first_available_warehouse.id\n",
    "            warehouse_name = first_available_warehouse.name\n",
    "            warehouse_state = first_available_warehouse.state.value\n",
    "\n",
    "            print(\"\\n--- First Available SQL Warehouse Details ---\")\n",
    "            print(f\"ID: {warehouse_id}\")\n",
    "        else:\n",
    "            print(\"Could not determine an available SQL warehouse ID.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure your Databricks authentication is correctly configured and you have permissions to list SQL warehouses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4b4a2dc-2606-4e12-affb-bc7b9eb0ebb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#deploy app\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service import apps\n",
    "from databricks.sdk.service.apps import App, AppResource, AppDeployment, AppResourceSqlWarehouse, AppResourceSqlWarehouseSqlWarehousePermission\n",
    "from pathlib import Path\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "current_notebook_path = dbutils.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "# Use pathlib to handle path manipulation robustly\n",
    "current_notebook_dir = Path(current_notebook_path).parent.parent.parent\n",
    "full_app_notebook_path = (current_notebook_dir / 'apps/src/').resolve()\n",
    "\n",
    "# Convert the Path object back to a string for the API\n",
    "directory_path = str(full_app_notebook_path)\n",
    "\n",
    "#handle name length constraints\n",
    "app_name = f\"{schema_name.lower().replace('_', '-')}-app\"\n",
    "if len(app_name) > 30:\n",
    "    parts = app_name.split('-')\n",
    "    while len('-'.join(parts)) > 30 and len(parts) > 1:\n",
    "        parts.pop(0)\n",
    "    app_name = '-'.join(parts)\n",
    "\n",
    "warehouse = AppResourceSqlWarehouse(\n",
    "    id=warehouse_id,\n",
    "    permission=AppResourceSqlWarehouseSqlWarehousePermission.CAN_USE\n",
    ")\n",
    "\n",
    "warehouse_resource = AppResource(name=\"sql-warehouse\", sql_warehouse=warehouse)\n",
    "\n",
    "evaluation_app = App(name=app_name, \n",
    "              description=\"Demo Iron Ore Processing App\", \n",
    "              default_source_code_path=directory_path,\n",
    "              resources=[warehouse_resource],\n",
    "              user_api_scopes=['sql']\n",
    "              )\n",
    "\n",
    "app_details = w.apps.create_and_wait(app=evaluation_app)\n",
    "print(app_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45bc43a4-0744-4640-8282-05499af31f47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "current_notebook_dir = Path(current_notebook_path).parent.parent.parent\n",
    "full_app_notebook_path = (current_notebook_dir / 'apps/src/').resolve()\n",
    "\n",
    "# Convert the Path object back to a string for the API\n",
    "directory_path = str(full_app_notebook_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8ba9170-900d-43b1-89f2-1500821bc008",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "deployment = AppDeployment(\n",
    "  source_code_path=f\"/Workspace{directory_path}\"\n",
    ")\n",
    "\n",
    "resp = w.apps.deploy_and_wait(app_name=app_name, app_deployment=deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bd4e166-248c-4a28-9d0c-0dde1f33feb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config_path = f'./config.json'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config['app_url'] = app_details.url\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8ddc67a-a848-4f78-9b76-7af79a214320",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04.create_app",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
