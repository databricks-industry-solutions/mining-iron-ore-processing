{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35d2468c-cda5-456c-b03c-3a8d0702c34c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow\n",
    "dbutils.library.restartPython() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4fafa23-7ef7-406f-b012-ac9902170d42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74c7cfff-08cf-4511-84f3-27e99c6967b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# TODO: Update these values as necessary\n",
    "\n",
    "\n",
    "# TODO: Create notebooks for each task and populate the notebook path here, replacing the INVALID PATHS LISTED BELOW.\n",
    "# These paths should correspond to where you put the notebooks templated from the example deployment jobs template notebook\n",
    "# in your Databricks workspace.\n",
    "\n",
    "current_notebook_path = dbutils.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "# Use pathlib to handle path manipulation robustly\n",
    "current_notebook_dir = Path(current_notebook_path).parent\n",
    "\n",
    "evaluation_notebook_path = f\"{current_notebook_dir}/model_deploy_jobs/evaluation\"\n",
    "approval_notebook_path = f\"{current_notebook_dir}/model_deploy_jobs/approval\"\n",
    "deployment_notebook_path = f\"{current_notebook_dir}/model_deploy_jobs/deployment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c90654e7-09c9-4710-835b-8050001a34d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create job with necessary configuration to connect to model as deployment job\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service import jobs\n",
    "import mlflow\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "client = MlflowClient(registry_uri=\"databricks-uc\")\n",
    "w = WorkspaceClient()\n",
    "\n",
    "def create_deployment_job(model_element:str):\n",
    "    model_name = f\"{catalog_name}.{schema_name}.{model_element}_model\" # The name of the already created UC Model\n",
    "    job_name = f\"demo_mining_processing_{model_element}_model_deploy\" # The desired name of the deployment job\n",
    "    job_settings = jobs.JobSettings(\n",
    "        name=job_name,\n",
    "        tasks=[\n",
    "            #TODO: fix up evaluation\n",
    "            # jobs.Task(\n",
    "            #     task_key=\"Evaluation\",\n",
    "            #     notebook_task=jobs.NotebookTask(notebook_path=evaluation_notebook_path),\n",
    "            #     max_retries=0,\n",
    "            # ),\n",
    "            jobs.Task(\n",
    "                task_key=\"Approval_Check\",\n",
    "                notebook_task=jobs.NotebookTask(\n",
    "                    notebook_path=approval_notebook_path,\n",
    "                    base_parameters={\"approval_tag_name\": \"{{task.name}}\"}\n",
    "                ),\n",
    "                #depends_on=[jobs.TaskDependency(task_key=\"Evaluation\")],\n",
    "                max_retries=0,\n",
    "            ),\n",
    "            jobs.Task(\n",
    "                task_key=\"Deployment\",\n",
    "                notebook_task=jobs.NotebookTask(notebook_path=deployment_notebook_path),\n",
    "                depends_on=[jobs.TaskDependency(task_key=\"Approval_Check\")],\n",
    "                max_retries=0,\n",
    "            ),\n",
    "        ],\n",
    "        parameters=[\n",
    "            jobs.JobParameter(name=\"model_name\", default=model_name),\n",
    "            jobs.JobParameter(name=\"model_version\", default=\"\"),\n",
    "        ],\n",
    "        queue=jobs.QueueSettings(enabled=True),\n",
    "        max_concurrent_runs=1,\n",
    "    )\n",
    "\n",
    "    created_job = w.jobs.create(**job_settings.__dict__)\n",
    "\n",
    "    print(f\"job created with id: {created_job.job_id}\")\n",
    "    print(f\"applying to model {model_name}\")\n",
    "    try:\n",
    "        if client.get_registered_model(model_name):\n",
    "            client.update_registered_model(model_name, deployment_job_id=created_job.job_id)\n",
    "            print(\"Model updated\")\n",
    "    except mlflow.exceptions.RestException:\n",
    "        print(\"Model does not exist\")\n",
    "        client.create_registered_model(model_name, deployment_job_id=created_job.job_id)\n",
    "\n",
    "    print(f\"Deployment Job {job_name} Created for Model: {model_name}\")\n",
    "\n",
    "#create the two model deployment jobs\n",
    "for model_name in [\"fe\", \"si\"]:    create_deployment_job(model_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02.create-deployment-job",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
